{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading the titanic dataset\n",
    "\n",
    "Before starting any work on building an ML pipeline, we first need to make our data available for Azure ML. To do so, we'll simply upload the files to our default datastore (blob storage) for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "workspace = Workspace.from_config()\n",
    "datastore = workspace.get_default_datastore()\n",
    "\n",
    "datastore.upload_files(\n",
    "    files=[\n",
    "        '../../../datasets/titanic/train.csv', \n",
    "        '../../../datasets/titanic/validation.csv'\n",
    "    ],\n",
    "    target_path='titanic',\n",
    "    overwrite=True,\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could upload (and register) our titanic dataset as an Azure Dataset, which would potentially give us some extra features such as version of the dataset. For now, we'll keep that as an extra exercise ;)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
